{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "print('TensorFlow ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def get_distances(embeddings):\n",
    "    \"\"\"embeddings : shape == [batch_size, EMBEDDING_DIM]\n",
    "       return distances : shape == [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    dot = tf.matmul(embeddings, embeddings, transpose_b=True)\n",
    "    squared_norms = tf.expand_dims(tf.linalg.diag_part(dot), 0)\n",
    "    squared_norms_t = tf.transpose(squared_norms)\n",
    "    squared_distances = squared_norms + squared_norms_t - 2 * dot\n",
    "\n",
    "    zero_mask = tf.equal(squared_distances, 0)\n",
    "    squared_distances = squared_distances + tf.cast(zero_mask, dtype=tf.float32)*1e-14\n",
    "    distances = tf.sqrt(squared_distances)\n",
    "    distances = distances * (1 - tf.cast(zero_mask, dtype=tf.float32))\n",
    "    return distances\n",
    "\n",
    "def get_negative_mask(labels):\n",
    "    \"\"\"label(a) != label(b)\"\"\"\n",
    "    labels = tf.expand_dims(labels, axis=1)\n",
    "    labels_t = tf.transpose(labels)\n",
    "    mask = tf.logical_not(tf.equal(labels, labels_t))\n",
    "    return mask\n",
    "\n",
    "def get_positive_mask(labels):\n",
    "    \"\"\"label(a) == label(b) && a != b \"\"\"\n",
    "    batch_shape = tf.shape(labels)[0]\n",
    "    mask_1 = tf.logical_not(get_negative_mask(labels))\n",
    "    mask_2 = tf.logical_not(tf.eye(batch_shape, dtype=tf.bool))\n",
    "    return tf.logical_and(mask_1, mask_2)\n",
    "\n",
    "def triplet_loss(labels, embeddings, margin=0.5):\n",
    "    \"\"\"embeddings : shape == [batch_size, EMBEDDING_DIM]\n",
    "       labels : shape == [batch_size]\n",
    "    \"\"\"\n",
    "    distances = get_distances(embeddings)\n",
    "    positive_mask = get_positive_mask(labels)\n",
    "    negative_mask = get_negative_mask(labels)\n",
    "\n",
    "    ## hard positive samples\n",
    "    positive_distances = tf.cast(positive_mask, dtype=tf.float32) * distances\n",
    "    hard_positive_distances = tf.expand_dims(tf.reduce_max(positive_distances, axis=1), axis=1)\n",
    "\n",
    "    ## hard negative samples\n",
    "    max_distance = tf.expand_dims(tf.reduce_max(distances, axis=1), axis=1)\n",
    "    hard_negative_distaces = tf.expand_dims(tf.reduce_min(distances + (1 - tf.cast(negative_mask, dtype=tf.float32)) * max_distance, axis=1), axis=1)\n",
    "    \n",
    "    ## final loss\n",
    "    loss = hard_positive_distances - hard_negative_distaces + margin\n",
    "    loss = tf.maximum(loss, 0)\n",
    "    return tf.reduce_mean(loss, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = tfds.load('mnist', split=['train', 'test'])\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    image = tf.cast(sample['image'], dtype=tf.float32) / 255.\n",
    "    label = sample['label']\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(4096)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(4096)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(tensor, nfilters, kernel_size=3, strides=1):\n",
    "    y = tf.keras.layers.Conv2D(filters=nfilters, \n",
    "                               kernel_size=(3, 3), \n",
    "                               padding='valid', \n",
    "                               strides=strides, \n",
    "                               use_bias=False, \n",
    "                               kernel_initializer='he_normal', \n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=1e-4))(tensor)\n",
    "    y = tf.keras.layers.BatchNormalization()(y)\n",
    "    y = tf.keras.layers.ReLU()(y)\n",
    "    return y\n",
    "\n",
    "def model_fn():\n",
    "    input_layer = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "    x = conv_block(input_layer, nfilters=16, kernel_size=3, strides=1)\n",
    "    x = conv_block(x, nfilters=32, kernel_size=3, strides=1)\n",
    "    x = conv_block(x, nfilters=64, kernel_size=3, strides=2)\n",
    "    x = conv_block(x, nfilters=64, kernel_size=3, strides=1)\n",
    "    x = conv_block(x, nfilters=64, kernel_size=3, strides=1)\n",
    "    output_layer = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    return tf.keras.Model(inputs=[input_layer], outputs=[output_layer], name='embedding_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "model.summary()\n",
    "epochs = 50\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "@tf.function()\n",
    "def train_fn(images, labels):\n",
    "    with tf.GradientTape() as Tape:\n",
    "        embeddings = model(images, training=True)\n",
    "        loss = triplet_loss(labels, embeddings)\n",
    "    gradients = Tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function()\n",
    "def validation_fn(images, labels):\n",
    "    embeddings = model(images, training=True)\n",
    "    loss = triplet_loss(labels, embeddings)\n",
    "    return loss\n",
    "\n",
    "batch_losses = []\n",
    "validation_losses = []\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_loss_vaidation = []\n",
    "    print('Epoch {}/{}'.format(ep+1, epochs))\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        loss = train_fn(images, labels)\n",
    "        loss_numpy = loss[0].numpy()\n",
    "        epoch_loss.append(loss)\n",
    "#         if step % 25 == 0:\n",
    "#             print('Loss at epoch {} step {} = {:.4f}'.format(ep+1, step + 1, loss_numpy))        \n",
    "    mean_loss = np.mean(epoch_loss)\n",
    "    batch_losses.append(mean_loss)\n",
    "    print('Loss at end of {} epochs = {:.4f}'.format(ep+1, mean_loss))\n",
    "    \n",
    "    for step, batch in enumerate(test_dataset):\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        loss = validation_fn(images, labels)\n",
    "        loss_numpy = loss[0].numpy()\n",
    "        epoch_loss_vaidation.append(loss)\n",
    "    val_mean_loss = np.mean(epoch_loss_vaidation)\n",
    "    validation_losses.append(val_mean_loss)\n",
    "    print('Validation loss at end of {} epochs = {:.4f}\\n'.format(ep+1, val_mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(batch_losses)\n",
    "plt.plot(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros(shape=[10000, 64])\n",
    "images = np.zeros(shape=[10000, 28, 28, 1])\n",
    "labels = np.zeros(shape=[10000])\n",
    "test_data = tfds.load('mnist', split=['test'])[0]\n",
    "for i, sample in tqdm_notebook(enumerate(test_data.take(10000))):\n",
    "    img = sample['image']\n",
    "    images[i] = img.numpy()\n",
    "    embedding = model(tf.cast(img[None, ...], dtype=tf.float32)/255.)[0]\n",
    "    embeddings[i] = embedding.numpy()\n",
    "    labels[i] = np.uint8(sample['label'].numpy())\n",
    "embeddings = tf.constant(embeddings, dtype=tf.float32)\n",
    "labels = tf.constant(labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.dot_embeddings = tf.matmul(embeddings, embeddings, transpose_b=True)\n",
    "        self.squared_norms_embeddings = tf.expand_dims(tf.linalg.diag_part(self.dot_embeddings), 0)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def get_labels(self, query_vector, top_k=None):\n",
    "        dot_query_vector = tf.matmul(query_vector, query_vector, transpose_b=True)\n",
    "        squared_norms_query_vector = tf.expand_dims(tf.linalg.diag_part(dot_query_vector), 0)\n",
    "        dot_product = tf.reduce_sum(self.embeddings * query_vector, axis=1)\n",
    "        distances = tf.maximum(self.squared_norms_embeddings + squared_norms_query_vector - 2 * dot_product, 0)\n",
    "        sorted_indices =  tf.argsort(distances)\n",
    "        if top_k:\n",
    "            sorted_indices = sorted_indices[..., :top_k]\n",
    "        nearest_labels =  tf.reshape(tf.gather(self.labels, sorted_indices), shape=[-1, 1])\n",
    "        nearest_distances = tf.reshape(tf.gather(distances[0], sorted_indices), shape=[-1, 1])\n",
    "        return nearest_distances[..., 0], nearest_labels[..., 0], sorted_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 569\n",
    "query_v = embeddings[i][None,...]\n",
    "query_img = images[i]\n",
    "query_label = labels[i]\n",
    "\n",
    "index = Index(embeddings, labels)\n",
    "distances_, labels_, indices_ = index.get_labels(query_v, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('Query Image')\n",
    "plt.axis('off')\n",
    "plt.imshow(query_img[..., 0])\n",
    "plt.subplots(2, 5, figsize=(15, 8))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.title(labels_[i].numpy())\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[indices_[i]][..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
